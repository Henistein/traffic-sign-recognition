{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data \n",
    "import pandas as pd\n",
    "\n",
    "def get_names():\n",
    "  names = pd.read_csv('signnames.csv')\n",
    "  for i in names['ClassId']:\n",
    "    yield i\n",
    "\n",
    "folder = []\n",
    "for i in glob.glob('data_train/*'):\n",
    "  folder.append(i)\n",
    "  \n",
    "folder.sort()\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "gen = get_names()\n",
    "for i in folder:\n",
    "  aux = next(gen)\n",
    "  for j in glob.glob((i+'/*.ppm')):\n",
    "    images.append(j)\n",
    "    labels.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "for i in images:\n",
    "  image_list.append(imread(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to resize an image to (33, 33)\n",
    "resize_img = lambda x: np.array(Image.fromarray(x).resize((33, 33)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "rawX = np.array([resize_img(i) for i in image_list]).astype('float')\n",
    "rawY = np.array(labels)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(rawX, rawY, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.l1 = nn.Linear(3267, 1280, bias=False)\n",
    "    self.l2 = nn.Linear(1280, 43, bias=False)\n",
    "    self.sm = nn.LogSoftmax(dim=1)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.l1(x))\n",
    "    x = self.l2(x)\n",
    "    x = self.sm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.66 accuracy 0.81: 100%|██████████| 1000/1000 [04:10<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.6637769341468811\n",
      "Accuracy:  0.807812511920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc248d27e80>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.0)\n",
    "losses, accuracies = [], []\n",
    "BS = 1280\n",
    "for i in (t := trange(1000)):\n",
    "  samp = np.random.randint(0, X_train.shape[0], size=BS)\n",
    "  X = torch.tensor(X_train[samp].reshape((-1, 33*33*3))).float()\n",
    "  Y = torch.tensor(Y_train[samp]).long()\n",
    "  model.zero_grad()\n",
    "  \n",
    "  # forward (contains activation function inside)\n",
    "  out = model(X)\n",
    "  \n",
    "  # loss function\n",
    "  loss = loss_function(out, Y)\n",
    "  loss = loss.mean()\n",
    "  \n",
    "  # Bacward and optimizer\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "  \n",
    "  # Stats\n",
    "  cat = torch.argmax(out, dim=1)\n",
    "  accuracy = (cat == Y).float().mean()\n",
    "  accuracy = accuracy.item()\n",
    "  loss = loss.item()\n",
    "  accuracies.append(accuracy)\n",
    "  losses.append(loss)\n",
    "  t.set_description(\"loss %.2f accuracy %.2f\" % (loss, accuracy))\n",
    "\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "plot(losses)\n",
    "plot(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710904825053555"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eval\n",
    "Y_pred = torch.argmax(model(torch.tensor(X_test.reshape((-1, 33*33*3))).float()), dim=1).numpy()\n",
    "(Y_test == Y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "# https://navoshta.com/traffic-signs-classification/\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16*5*5, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 43)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 33, 33, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 3, 5, 5], expected input[3, 33, 33, 1280] to have 3 channels, but got 33 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-02e1851d6796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# forward (contains activation function inside)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-1ac6c430bd45>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 3, 5, 5], expected input[3, 33, 33, 1280] to have 3 channels, but got 33 channels instead"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.0)\n",
    "\n",
    "losses, accuracies = [], []\n",
    "BS = 1280\n",
    "for i in (t := trange(1000)):\n",
    "  samp = np.random.randint(0, X_train.shape[0], size=BS)\n",
    "  X = torch.tensor(X_train[samp].T).float()\n",
    "  print(X.shape)\n",
    "  Y = torch.tensor(Y_train[samp]).long()\n",
    "  net.zero_grad()\n",
    "  \n",
    "  # forward (contains activation function inside)\n",
    "  out = net(X)\n",
    "  \n",
    "  # loss function\n",
    "  loss = loss_function(out, Y)\n",
    "  loss = loss.mean()\n",
    "  \n",
    "  # Bacward and optimizer\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "  \n",
    "  # Stats\n",
    "  cat = torch.argmax(out, dim=1)\n",
    "  accuracy = (cat == Y).float().mean()\n",
    "  accuracy = accuracy.item()\n",
    "  loss = loss.item()\n",
    "  accuracies.append(accuracy)\n",
    "  losses.append(loss)\n",
    "  t.set_description(\"loss %.2f accuracy %.2f\" % (loss, accuracy))\n",
    "plot(losses)\n",
    "plot(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
